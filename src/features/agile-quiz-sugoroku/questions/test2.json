[
  {
    "question": "回帰テストの目的は？",
    "options": [
      "変更後に既存機能が壊れてないか確認",
      "新機能のみ確認",
      "パフォーマンス計測",
      "セキュリティ検証"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "回帰テストで既存機能の破壊を検出。"
  },
  {
    "question": "リリース前に最も重視される品質観点は？",
    "options": [
      "クリティカルな不具合がないこと",
      "コードが美しい",
      "全テスト自動化",
      "ドキュメント完全"
    ],
    "answer": 0,
    "tags": ["testing", "release"],
    "explanation": "リリース判定ではクリティカルな不具合の有無が最優先される。"
  },
  {
    "question": "E2Eテストが検証する範囲は？",
    "options": [
      "システム全体のユーザーシナリオ",
      "関数単体",
      "モジュール間接続",
      "DBのみ"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "E2Eテストはユーザー操作を模倣し、システム全体の動作を検証する。"
  },
  {
    "question": "リリース判定で確認すべき事項は？",
    "options": [
      "既知不具合の影響度と対応方針",
      "コード行数",
      "開発者人数",
      "会議回数"
    ],
    "answer": 0,
    "tags": ["release", "testing"],
    "explanation": "リリース判定では既知不具合の影響度と対応方針を確認し、出荷可否を判断する。"
  },
  {
    "question": "カナリアリリースとは？",
    "options": [
      "一部ユーザーに先行リリース",
      "深夜リリース",
      "全ユーザー一斉",
      "テスト環境のみ"
    ],
    "answer": 0,
    "tags": ["release"],
    "explanation": "カナリアリリースでリスクを限定。"
  },
  {
    "question": "受け入れテストの主な実施者は？",
    "options": [
      "POやステークホルダー",
      "開発者のみ",
      "QAのみ",
      "AIツール"
    ],
    "answer": 0,
    "tags": ["testing", "scrum"],
    "explanation": "受け入れテストはPOやステークホルダーがビジネス要件を満たすか確認するために行う。"
  },
  {
    "question": "テストピラミッドで最も数が多いべきテストは？",
    "options": [
      "単体テスト",
      "E2Eテスト",
      "結合テスト",
      "手動テスト"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "ピラミッド底辺＝単体テストが最多。"
  },
  {
    "question": "フレイキーテストとは？",
    "options": [
      "同条件で結果が変わる不安定なテスト",
      "高速テスト",
      "古いテスト",
      "手動テスト"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "フレイキーテストは同じ条件でも成功・失敗が変わり、CI信頼性を低下させる。"
  },
  {
    "question": "ブルーグリーンデプロイメントの特徴は？",
    "options": [
      "2環境切替でダウンタイムなし",
      "環境を青く表示",
      "環境を緑に統一",
      "1環境で段階更新"
    ],
    "answer": 0,
    "tags": ["release"],
    "explanation": "本番と待機の2環境を用意し、切替によりダウンタイムゼロのリリースを実現する。"
  },
  {
    "question": "非機能テストに含まれるものは？",
    "options": [
      "性能・負荷テスト",
      "単体テスト",
      "結合テスト",
      "受け入れテスト"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "非機能テストは性能・負荷・セキュリティなど機能以外の品質特性を検証する。"
  },
  {
    "question": "A/Bテストの目的は？",
    "options": [
      "2つのバリエーションの効果を比較",
      "ABの順序テスト",
      "ABCの分類",
      "2回テスト"
    ],
    "answer": 0,
    "tags": ["release", "testing"],
    "explanation": "A/Bテストは2つのバリエーションをユーザーに提示し、効果の差を統計的に比較する。"
  },
  {
    "question": "テスト自動化で最も重要な考慮点は？",
    "options": [
      "メンテナンスコスト",
      "実行速度のみ",
      "テスト数のみ",
      "ツール価格"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "自動テストは作成後の維持・修正コストが大きく、メンテナンス性が最重要となる。"
  },
  {
    "question": "ダークローンチとは？",
    "options": [
      "ユーザーに見せず本番で機能を稼働",
      "夜間リリース",
      "秘密リリース",
      "テスト環境リリース"
    ],
    "answer": 0,
    "tags": ["release"],
    "explanation": "ダークローンチはユーザーに公開せず本番環境で新機能を動作させ、安全性を確認する手法。"
  },
  {
    "question": "SLIとは？",
    "options": [
      "サービス品質の定量的指標",
      "セキュリティ指標",
      "コスト指標",
      "開発速度指標"
    ],
    "answer": 0,
    "tags": ["sre"],
    "explanation": "SLI（Service Level Indicator）はレイテンシや可用性などサービス品質を定量的に測る指標。"
  },
  {
    "question": "ロールバック戦略が重要な理由は？",
    "options": [
      "リリース失敗時に迅速復旧",
      "テスト省略",
      "開発速度向上",
      "コスト削減"
    ],
    "answer": 0,
    "tags": ["release"],
    "explanation": "リリース失敗時に迅速に前バージョンへ戻せることで、障害影響を最小化できる。"
  },
  {
    "question": "E2Eテストの主な検証対象は？",
    "options": [
      "ユーザー視点のシステム連携動作",
      "関数単体の分岐網羅",
      "コンパイラ最適化の有無",
      "命名規則のみ"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "E2Eテストはユーザー視点でシステム全体の連携が正しく動作するかを検証する。"
  },
  {
    "question": "カナリアリリースの利点は？",
    "options": [
      "限定公開でリスクを抑えて検証できる",
      "全ユーザーへ同時展開できる",
      "監視が不要になる",
      "ロールバックできなくなる"
    ],
    "answer": 0,
    "tags": ["release"],
    "explanation": "一部ユーザーに限定して公開することで、問題発生時の影響範囲を最小限に抑えられる。"
  },
  {
    "question": "負荷テストの主目的は？",
    "options": [
      "想定トラフィック下の性能限界を把握する",
      "UI色を確認する",
      "命名規則を確認する",
      "会議頻度を測る"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "負荷テストにより想定トラフィック下でのシステム性能限界やボトルネックを把握できる。"
  },
  {
    "question": "スモークテストを実施する理由は？",
    "options": [
      "主要機能の致命的不具合を早期検出する",
      "詳細仕様を全確認する",
      "全ケースを手動化する",
      "監視を停止する"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "スモークテストは主要機能の致命的不具合を素早く検出し、詳細テストの前に判断できる。"
  },
  {
    "question": "ステージング環境を本番に近づける価値は？",
    "options": [
      "環境差異による不具合を減らせる",
      "本番監視が不要になる",
      "障害が消える",
      "テスト設計が不要になる"
    ],
    "answer": 0,
    "tags": ["release", "testing"],
    "explanation": "ステージングを本番に近づけることで環境差異に起因する不具合を事前に発見できる。"
  },
  {
    "question": "非同期処理のテストで重要な観点は？",
    "options": [
      "完了条件とタイミング依存の検証",
      "画面配色のみ",
      "コメント量のみ",
      "コミット頻度のみ"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "非同期処理は完了タイミングが不定のため、完了条件やタイミング依存を適切に検証する必要がある。"
  },
  {
    "question": "性能劣化の検知に有効なのは？",
    "options": [
      "継続的なベンチマーク比較",
      "リリース後の勘",
      "障害時のみ測定",
      "測定結果を破棄"
    ],
    "answer": 0,
    "tags": ["sre", "testing"],
    "explanation": "継続的にベンチマークを比較することで、性能劣化の傾向を早期に検知できる。"
  },
  {
    "question": "カバレッジ100%でも品質保証できない理由は？",
    "options": [
      "観点不足や期待値誤りがあり得るため",
      "計測が常に誤っているため",
      "単体テストが無価値なため",
      "自動化が禁止されるため"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "カバレッジは行の通過を示すだけで、テスト観点の網羅性や期待値の正しさは保証しない。"
  },
  {
    "question": "契約変更時に優先して更新すべきテストは？",
    "options": [
      "影響する契約・統合テスト",
      "UIスナップショットのみ",
      "性能テストのみ",
      "監視アラートのみ"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "契約変更時はAPI間の互換性を検証する契約・統合テストを優先的に更新すべき。"
  },
  {
    "question": "シャドーテストの目的は？",
    "options": [
      "本番同等入力で新実装挙動を比較する",
      "テストを非公開にするだけ",
      "夜間のみ実行する",
      "結果を保存しない"
    ],
    "answer": 0,
    "tags": ["testing", "release"],
    "explanation": "シャドーテストは本番トラフィックを複製して新旧実装の挙動を比較し、安全性を確認する。"
  },
  {
    "question": "テストデータ管理で避けるべきことは？",
    "options": [
      "個人情報をマスキングせず使うこと",
      "匿名化データを使うこと",
      "生成データを使うこと",
      "最小データを使うこと"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "テストデータに個人情報をマスキングせず使用するとプライバシー侵害や法令違反のリスクがある。"
  },
  {
    "question": "監視アラートのテストを行う理由は？",
    "options": [
      "検知から通知までの導線を確認するため",
      "通知を減らすためだけ",
      "障害対応をなくすため",
      "監視を停止するため"
    ],
    "answer": 0,
    "tags": ["sre", "testing"],
    "explanation": "監視アラートの検知・通知導線が正しく機能することを事前に確認し、障害時の対応遅延を防ぐ。"
  },
  {
    "question": "負荷試験での成功基準として適切なのは？",
    "options": [
      "SLOに対する閾値を満たすこと",
      "CPU使用率ゼロ",
      "エラーゼロのみ",
      "応答時間未計測"
    ],
    "answer": 0,
    "tags": ["sre", "testing"],
    "explanation": "SLOで定めた閾値（レイテンシ・エラー率等）を基準にすることで客観的な合否判定ができる。"
  },
  {
    "question": "テスト環境のデータ初期化が必要な理由は？",
    "options": [
      "ケース間の独立性を保つため",
      "実行時間を増やすため",
      "失敗を隠すため",
      "ログを消すため"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "テストケース間でデータを初期化し独立性を保つことで、実行順序に依存しない安定した結果を得られる。"
  },
  {
    "question": "ユーザビリティテストで確認したいことは？",
    "options": [
      "ユーザーが目的を達成できるか",
      "コード行数",
      "CIの実行回数",
      "サーバー台数"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "ユーザビリティテストは実際のユーザーが迷わず目的を達成できるかを検証する。"
  },
  {
    "question": "障害注入テストの価値は？",
    "options": [
      "回復性とフォールトトレランスを検証できる",
      "障害を増やすだけ",
      "監視を不要化する",
      "設計を固定化する"
    ],
    "answer": 0,
    "tags": ["sre", "testing"],
    "explanation": "意図的に障害を注入することで、システムの回復性や耐障害性を事前に検証できる。"
  },
  {
    "question": "リリースゲートにテスト結果を使う利点は？",
    "options": [
      "客観的な品質判定ができる",
      "責任所在を曖昧にできる",
      "レビュー不要になる",
      "仕様調整が不要になる"
    ],
    "answer": 0,
    "tags": ["release", "testing"],
    "explanation": "テスト結果を基準にすることで属人的判断を排し、客観的な品質判定でリリース可否を決められる。"
  },
  {
    "question": "契約テスト失敗時にまず行うことは？",
    "options": [
      "変更差分と互換性影響を確認する",
      "無条件でデプロイする",
      "通知を止める",
      "テストを削除する"
    ],
    "answer": 0,
    "tags": ["testing"],
    "explanation": "契約テスト失敗時は変更差分を確認し、互換性への影響範囲を特定することが先決。"
  },
  {
    "question": "本番監視とテストの関係として適切なのは？",
    "options": [
      "監視は運用中の品質検証を補完する",
      "テストを完全代替する",
      "監視は不要",
      "どちらも不要"
    ],
    "answer": 0,
    "tags": ["sre", "testing"],
    "explanation": "テストはリリース前の品質確認、監視はリリース後の品質検証であり、両者は補完関係にある。"
  },
  {
    "question": "性能テストでP95を使う理由は？",
    "options": [
      "遅い側の体験を把握しやすい",
      "平均値と同じ意味だから",
      "最小値のみ見たいから",
      "外れ値を無視するため"
    ],
    "answer": 0,
    "tags": ["sre", "testing"],
    "explanation": "P95は上位5%の遅いリクエストの体験を可視化し、平均値では見えない問題を把握できる。"
  },
  {
    "question": "リハーサルリリースの価値は？",
    "options": [
      "手順・権限・時間見積もりを検証できる",
      "本番リリース不要になる",
      "監視停止できる",
      "障害報告を省ける"
    ],
    "answer": 0,
    "tags": ["release"],
    "explanation": "リハーサルにより手順・権限・所要時間を事前検証し、本番リリースのリスクを低減できる。"
  },
  {
    "question": "品質ゲートを厳しくし過ぎるリスクは？",
    "options": [
      "リードタイム悪化とのバランス課題",
      "品質が必ず下がる",
      "テストが不要になる",
      "障害が必ず増える"
    ],
    "answer": 0,
    "tags": ["release", "testing"],
    "explanation": "品質ゲートを厳しくし過ぎるとリードタイムが悪化し、デリバリー速度とのバランスが課題となる。"
  }
]
